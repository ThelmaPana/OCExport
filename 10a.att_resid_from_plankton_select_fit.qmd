---
title: "Predict POC remaining residuals values from plankton"
subtitle: "Train a XGBoost model to predict POC remaining residuals values from selected plankton diversity data."
author: "Thelma Panaïotis"
format:
  html:
    toc: true
    embed-resources: true
editor: visual
execute:
  cache: true
  warning: false
---

## Set-up and load data

```{r set_up}
#| output: false
#| cache: false
source("utils.R")
load("data/04.all_data.Rdata")
output_filename <- "data/10.att_resid_from_plankton_select_fit.Rdata"
```

## Data preparation

### Response variable

Let’s have a look at our response variable: POC value. We do not need to inspect response variables as the model we are going to use are robust to non-normal distributions.

```{r poc_hist}
df %>% ggplot() + geom_histogram(aes(x = resid_remain), bins = 100)
```

### Variable roles

```{r roles}
# Response variable
resp_var <- c("resid_remain") # keep both untransformed and transformed predictor
# Explanatory variables
#exp_vars <- df %>% select(contains("mo")) %>% colnames()
#exp_vars <- df %>% select(prop_crustacea:mo_spe) %>% colnames()
exp_vars <- df %>% select(mo_ghet_mean, ss_inter, mo_size_sd) %>% colnames()
# Metadata
meta_vars <- c("lon", "lat")
```

### Explanatory variables

```{r exp_pca}
df_exp <- df %>% select(all_of(exp_vars))
exp_pca <- FactoMineR::PCA(df_exp, scale.unit = TRUE, graph = FALSE)
plot(exp_pca, choix = "var")

# Get eigenvalues
eig <- exp_pca$eig %>%
  as.data.frame() %>%
  rownames_to_column(var = "comp") %>%
  as_tibble() %>%
  mutate(
    comp = str_remove(comp, "comp "),
    comp = as.numeric(comp),
    comp = as.factor(comp)
    ) %>% 
  rename(var = `percentage of variance`, cum_var = `cumulative percentage of variance`)

eig %>%
  ggplot() +
  geom_col(aes(x = comp, y = eigenvalue)) +
  geom_hline(yintercept = 1, col = "red", linewidth = 0.5) +
  theme_classic() +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "PC", y = "Eigenvalue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Get coordinates of individuals
inds <- exp_pca$ind$coord %>% as_tibble() %>% select(Dim.1:Dim.3)
# Set nice names for columns
colnames(inds) <- str_c("dim_", paste(c(1:ncol(inds))))
df <- df %>% bind_cols(inds)

ggmap(df, var = "dim_1", type = "point", palette = div_pal)
ggmap(df, var = "dim_2", type = "point", palette = div_pal)

df %>% 
  select(lon, lat, contains("dim_")) %>% 
  pivot_longer(contains("dim_")) %>% 
  ggplot(aes(x = lat, y = value)) +
  geom_point(size = 0.5) + 
  geom_smooth() +
  coord_flip() +
  facet_wrap(~name, nrow = 1)

#exp_vars <- df %>% select(contains("dim_")) %>% colnames()
```

## Data split

To better assess the performance of our model and get a distribution of R² instead of a single value, we will use nested cross-validation.

Instead of splitting the data into train and test sets and get a single estimate of R² on the test set, we will use nested cross-validation so that we have several repeats of train/test splits and thus a distribution of R² values. For each fold, a second cross-validation is performed within the training set in order to tune the hyperparameters.

We use 10-fold cross-validation:

-   10% of data for testing

-   90% of data for training. This subset is used for nested cross-validation with:

    -   10% of data for validation

    -   90% of data for learning

Two different methods for data splitting are used:

-   stratified on deciles of the response variable (`log_remain_log`)

-   spatial cross-validation using blocks

```{r split}
# Number of folds
n_folds <- 5

# Transform dataframe to sf object for spatial CV.
df_sf <- st_as_sf(df, coords = c("lon", "lat"), crs = 4326)

#set.seed(seed)
## Bind together folds of both nested_cv
#folds <- bind_rows(
#  # Stratified CV on deciles of response variable
#  nested_cv(
#    df,
#    outside = vfold_cv(v = n_folds, strata = poc_log, breaks = 9),
#    inside = vfold_cv(v = n_folds, strata = poc_log, breaks = 9)) %>%
#    mutate(cv_type = "stratified"),
#  # Spatial CV
#  nested_cv(
#    df_sf,
#    outside = spatial_block_cv(v = n_folds),
#    inside = spatial_block_cv(v = n_folds)) %>%
#    mutate(cv_type = "spatial")
#)

#set.seed(seed)
folds <- nested_cv(
  df,
  outside = vfold_cv(v = n_folds, strata = resid_remain, breaks = 4),
  inside = vfold_cv(v = n_folds, strata = resid_remain, breaks = 4)) %>%
  mutate(cv_type = "stratified")
```

## Model definition

Let’s define a XGBoost regression model, with tunable hyperparameters:

-   `trees`: number of trees

-   `tree_depth`: maximum depth (i.e. number of splits) in a tree

-   `min_n`: minimum number of objects in a node to split further

-   `learn_rate`

```{r def_mod}
# Define a xgboost model with hyperparameters to tune
xgb_spec <- boost_tree(
  trees = tune(),
  tree_depth = tune(),
  min_n = tune(),
  learn_rate = tune()
) %>%
  set_mode("regression") %>%
  set_engine("xgboost")
```

We also generate the formula from the explanatory variables. We also keep poc for now, but it will be removed from predictors when generating the recipe within the gridsearch.

```{r def_form}
# Generate formula from list of explanatory variables
xgb_form <- as.formula(paste("resid_remain ~ ", paste(exp_vars, collapse = " + "), sep = ""))
```

Finally, let’s define the grid for the gridsearch (only one grid is used for all folds).

```{r def_grid}
# Define one grid for all folds
#set.seed(seed)
xgb_grid <- grid_latin_hypercube(
  trees(),
  learn_rate(),
  tree_depth(),
  min_n(),
  size = 30
)
```

## Models fitting

Let’s loop on cv folds. For each fold, a gridsearch is performed using nested CV on training data, and performance are assessed on the test data. This is run in parallel on `r n_cores` cores.

```{r gridsearch}
res <- mclapply(1:nrow(folds), function(i){
  
  ## Get fold
  x <- folds[i,]

  ## Train and test sets
  df_train <- analysis(x$splits[[1]]) %>% as_tibble()
  df_test <- assessment(x$splits[[1]]) %>% as_tibble()

  ## Recipe
  xgb_rec <- recipe(xgb_form, data = df_train) #%>%
    #update_role(remain, new_role = "untransformed outcome")

  ## Workflow
  xgb_wflow <- workflow() %>%
    add_recipe(xgb_rec) %>%
    add_model(xgb_spec)

  ## Gridsearch
  set.seed(seed)
  xgb_res <- tune_grid(
    xgb_wflow,
    resamples = x$inner_resamples[[1]],
    grid = xgb_grid,
    metrics = metric_set(rmse),
    control = control_grid(save_pred = TRUE)
  )
  best_params <- select_best(xgb_res)

  ## Final fit
  final_xgb <- finalize_workflow(
    xgb_wflow,
    best_params
  )
  final_res <- fit(final_xgb, df_train)

  ## Prediction on outer folds
  preds <- predict(final_res, new_data = df_test) %>%
    bind_cols(df_test %>% select(resid_remain))

  ## Model explainer
  # Select only predictors
  vip_train <- xgb_rec %>% prep() %>% bake(new_data = NULL, all_predictors())

  # Explainer
  xgb_explain <- explain_tidymodels(
      model = extract_fit_parsnip(final_res),
      data = vip_train,
      y = df_train %>%  pull(resid_remain),
      verbose = FALSE
    )

  # Variable importance
  full_vip <- model_parts(xgb_explain) %>%
    bind_rows() %>%
    filter(variable != "_baseline_")

  # CP profiles for all variables
  #selected_points <- ingredients::select_sample(df_train, n = 100, seed = seed)
  #cp_profiles <- ingredients::ceteris_paribus(xgb_explain, selected_points) %>% as_tibble()
  # CP profiles
  cp_profiles <- lapply(exp_vars, function(my_var){
    model_profile(explainer = xgb_explain, variables = my_var)$cp_profiles %>% as_tibble()
  }) %>%
    bind_rows()
  
  ## Return results
  return(tibble(
      preds = list(preds),
      importance = list(full_vip),
      cp_profiles = list(cp_profiles),
      fold = x$id,
      cv_type = x$cv_type
    ))
}, mc.cores = min(nrow(folds), 10)) %>%
  bind_rows()
```

## Save results

```{r save}
save(res, file = output_filename)
```

\
