---
title: "Predict POC values from plankton"
subtitle: "Train a XGBoost model to predict POC values from plankton diversity data."
author: "Thelma Panaïotis"
format:
  html:
    toc: true
    embed-resources: true
editor: visual
execute:
  cache: true
  warning: false
---

## Set-up and load data

```{r set_up}
#| output: false
#| cache: false
source("utils.R")
load("data/04.all_data.Rdata")
output_filename <- "data/13.poc_from_plankton_richness_fit.Rdata"
```

## Data preparation

### Response variable

Let’s have a look at our response variable: POC value. We do not need to inspect response variables as the model we are going to use are robust to non-normal distributions.

```{r poc_hist}
df %>% ggplot() + geom_histogram(aes(x = poc), bins = 100)
```

The distribution is not normal, this is problematic. Let’s try a log-transformation.

```{r poc_log_hist}
df <- df %>% mutate(poc_log = log(poc))
df %>% ggplot() + geom_histogram(aes(x = poc_log), bins = 100)
```

This is much better. We’ll then try to predict `log(poc)`.

### Merge predictors

-   `ta_ric_3 = specnumber(cont)/sqrt(rowSums(cont))`: number of species / sqrt(number of organisms) (Menhinick)

-   `ta_mast = specnumber(cont)/rowSums(cont)`: number of species / number of organisms

```{r pca_preds}
df_pca <- df %>% select(c("poc_log", "poc"), c("mo_ric", "ta_mast", "ta_ric_3"))
pca_res <- FactoMineR::PCA(df_pca, quanti.sup = 1:2, graph = FALSE)
plot(pca_res, choix = "var")
```

We note that:

-   both descriptors of taxonomic richness are correlated (positive on axis 1)

-   morphological richness is \~negatively correlated to taxonomic richness

-   poc is positively correlated with morphological richness and negatively correlated with taxonomic richness

### Links between predictors

```{r plots_preds}
ggplot(df, aes(x = ta_ric_3, y = ta_mast)) + geom_point() + geom_smooth()
ggplot(df) + geom_point(aes(x = ta_ric_3, y = mo_ric))
ggplot(df) + geom_point(aes(x = ta_mast, y = mo_ric))
```

### POC vs explanatory variables

```{r poc_vs_exp}
ggplot(df) + geom_point(aes(x = poc_log, y = ta_ric_3))
ggplot(df) + geom_point(aes(x = poc_log, y = ta_mast))
ggplot(df) + geom_point(aes(x = poc_log, y = mo_ric))
```

### Latitudinal effect?

```{r lat_effect}
#| fig-column: body-outset
#| out-width: 100%
df %>% 
  select(lat, poc, ta_ric_3, ta_mast, mo_ric) %>% 
  pivot_longer(poc:mo_ric, names_to = "variable") %>% 
  mutate(variable = factor(variable, levels = c("poc", "ta_ric_3", "ta_mast", "mo_ric"))) %>% 
  ggplot(aes(x = lat, y = value)) + 
  geom_point(size = 0.5) + 
  geom_smooth() +
  coord_flip() + 
  facet_wrap(~variable, ncol = 4, scales = "free_x")
```

Seems that we have a strong latitudinal effect.

### Variable roles

```{r roles}
# Response variable
resp_var <- c("poc_log", "poc") # keep both untransformed and transformed predictor
# Explanatory variables
# Define sets of explanatory variables
exp_vars_sets <- list(
  c("mo_ric", "ta_mast", "ta_ric_3"),
  c("mo_ric", "ta_mast"),
  c("mo_ric", "ta_ric_3"),
  c("ta_ric_3", "ta_mast"),
  c("ta_ric_3"),
  c("ta_mast"),
  c("mo_ric")
)
# Metadata
meta_vars <- c("lon", "lat")
```

## Data split

To better assess the performance of our model and get a distribution of R² instead of a single value, we will use nested cross-validation.

Instead of splitting the data into train and test sets and get a single estimate of R² on the test set, we will use nested cross-validation so that we have several repeats of train/test splits and thus a distribution of R² values. For each fold, a second cross-validation is performed within the training set in order to tune the hyperparameters.

We use 10-fold cross-validation:

-   10% of data for testing

-   90% of data for training. This subset is used for nested cross-validation with:

    -   10% of data for validation

    -   90% of data for learning

Two different methods for data splitting are used:

-   stratified on deciles of the response variable (`poc_log`)

-   spatial cross-validation using blocks

```{r split}
# Number of folds
n_folds <- 10

# Transform dataframe to sf object for spatial CV.
df_sf <- st_as_sf(df, coords = c("lon", "lat"), crs = 4326)

set.seed(seed)
# Bind together folds of both nested_cv
folds <- bind_rows(
  # Stratified CV on deciles of response variable
  nested_cv(
    df,
    outside = vfold_cv(v = n_folds, strata = poc_log, breaks = 9),
    inside = vfold_cv(v = n_folds, strata = poc_log, breaks = 9)) %>%
    mutate(cv_type = "stratified"),
  # Spatial CV
  nested_cv(
    df_sf,
    outside = spatial_block_cv(v = n_folds),
    inside = spatial_block_cv(v = n_folds)) %>%
    mutate(cv_type = "spatial")
)
```

## Model definition

Let’s define a XGBoost regression model, with tunable hyperparameters:

-   `trees`: number of trees

-   `tree_depth`: maximum depth (i.e. number of splits) in a tree

-   `min_n`: minimum number of objects in a node to split further

-   `learn_rate`

```{r def_mod}
# Define a xgboost model with hyperparameters to tune
xgb_spec <- boost_tree(
  trees = tune(),
  tree_depth = tune(),
  min_n = tune(),
  learn_rate = tune()
) %>%
  set_mode("regression") %>%
  set_engine("xgboost")
```

We also generate the formula from the explanatory variables. We also keep poc for now, but it will be removed from predictors when generating the recipe within the gridsearch.

Now we do this for every set of predictors.

```{r def_form}
# Generate formula from list of explanatory variables
#xgb_form <- as.formula(paste("poc_log ~ ", paste(c("poc", exp_vars), collapse = " + "), sep = ""))
```

Finally, let’s define the grid for the gridsearch (only one grid is used for all folds).

```{r def_grid}
# Define one grid for all folds
set.seed(seed)
xgb_grid <- grid_latin_hypercube(
  trees(),
  learn_rate(),
  tree_depth(),
  min_n(),
  size = 30
)
```

## Models fitting

Let’s loop on cv folds. For each fold, a gridsearch is performed using nested CV on training data, and performance are assessed on the test data. This is run in parallel on `r n_cores` cores.

```{r gridsearch}
res <- lapply(exp_vars_sets, function(exp_vars_set) {


  message(paste("Predicting from", paste0(exp_vars_set, collapse = " + ")))


  # Generate formula from list of explanatory variables
  xgb_form <- as.formula(paste("poc_log ~ ", paste(c("poc", exp_vars_set), collapse = " + "), sep = ""))

  res <- mclapply(1:nrow(folds), function(i){

    ## Get fold
    x <- folds[i,]

    ## Train and test sets
    df_train <- analysis(x$splits[[1]]) %>% as_tibble()
    df_test <- assessment(x$splits[[1]]) %>% as_tibble()

    ## Recipe
    xgb_rec <- recipe(xgb_form, data = df_train) %>%
      update_role(poc, new_role = "untransformed outcome")

    ## Workflow
    xgb_wflow <- workflow() %>%
      add_recipe(xgb_rec) %>%
      add_model(xgb_spec)

    ## Gridsearch
    set.seed(seed)
    xgb_res <- tune_grid(
      xgb_wflow,
      resamples = x$inner_resamples[[1]],
      grid = xgb_grid,
      metrics = metric_set(rmse),
      control = control_grid(save_pred = TRUE)
    )
    best_params <- select_best(xgb_res)

    ## Final fit
    final_xgb <- finalize_workflow(
      xgb_wflow,
      best_params
    )
    final_res <- fit(final_xgb, df_train)

    ## Prediction on outer folds
    preds <- predict(final_res, new_data = df_test) %>%
      bind_cols(df_test %>% select(poc_log))

    ## Model explainer
    # Select only predictors
    vip_train <- xgb_rec %>% prep() %>% bake(new_data = NULL, all_predictors())

    # Explainer
    xgb_explain <- explain_tidymodels(
      model = extract_fit_parsnip(final_res),
      data = vip_train,
      y = df_train %>%  pull(poc_log),
      verbose = FALSE
    )

    # Variable importance
    full_vip <- model_parts(
      xgb_explain,
      loss_function = loss_yardstick(yardstick::rsq),
      type = "raw"
    ) %>%
      bind_rows() %>%
      filter(variable != "_baseline_")

    # CP profiles for all variables
    #selected_points <- ingredients::select_sample(df_train, n = 100, seed = seed)
    #cp_profiles <- ingredients::ceteris_paribus(xgb_explain, selected_points) %>% as_tibble()
    # CP profiles
    if (length(exp_vars_set) > 1){
      cp_profiles <- lapply(exp_vars_set, function(my_var){
        model_profile(explainer = xgb_explain, variables = my_var)$cp_profiles %>% as_tibble()
      }) %>%
        bind_rows()
    } else {
      cp_profiles <- NA
    }

    ## Return results
    return(tibble(
      preds = list(preds),
      importance = list(full_vip),
      cp_profiles = list(cp_profiles),
      fold = x$id,
      cv_type = x$cv_type,
      predictor_set = paste0(exp_vars_set, collapse = " + ")
    ))
  }, mc.cores = 10) %>%
    bind_rows()

  return(res)
}) %>%
  bind_rows()
```

## Save results

```{r save}
save(res, file = output_filename)
```
