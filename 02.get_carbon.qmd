---
title: "Prepare carbon export data"
format:
  html:
    toc: true
editor: visual
---

```{r set_up}
#| output: false
source("utils.R")
```

## Model data − Wang et al.

### Read data

```{r read_wang}
#| fig-column: body-outset
#| out-width: 100%
poc_exp <- readMat("data/raw/Cexp_CAFE_kl24h.mat")$EXP[,,1]$POCexp
poc_100 <- readMat("data/raw/Cexp_CAFE_kl24h.mat")$EXP[,,1]$POC100
poc_1000 <- readMat("data/raw/Cexp_CAFE_kl24h.mat")$EXP[,,1]$POC1000

# Generate colnames as longitudes and rownames as latitudes
colnames(poc_exp) <- (c(0.5:179.5) * 2)
colnames(poc_100) <- (c(0.5:179.5) * 2)
colnames(poc_1000) <- (c(0.5:179.5) * 2)

rownames(poc_exp) <- (c(0:90) * 2) - 90
rownames(poc_100) <- (c(0:90) * 2) - 90
rownames(poc_1000) <- (c(0:90) * 2) - 90

# Convert to dataframes
poc_exp <- poc_exp %>%
  as.data.frame() %>%
  rownames_to_column(var = "lat") %>%
  as_tibble() %>%
  pivot_longer(cols = -lat, names_to = "lon", values_to = "poc_exp") %>%
  mutate(lat = as.numeric(lat), lon = as.numeric(lon)) %>%
  mutate(lon = ifelse(lon > 180, lon - 360, lon)) %>%
  mutate(poc_exp = ifelse(poc_exp == 0, NA, poc_exp)) 

poc_100 <- poc_100 %>%
  as.data.frame() %>%
  rownames_to_column(var = "lat") %>%
  as_tibble() %>%
  pivot_longer(cols = -lat, names_to = "lon", values_to = "poc_100") %>%
  mutate(lat = as.numeric(lat), lon = as.numeric(lon)) %>%
  mutate(lon = ifelse(lon > 180, lon - 360, lon)) %>%
  mutate(poc_100 = ifelse(poc_100 == 0, NA, poc_100)) 

poc_1000 <- poc_1000 %>%
  as.data.frame() %>%
  rownames_to_column(var = "lat") %>%
  as_tibble() %>%
  pivot_longer(cols = -lat, names_to = "lon", values_to = "poc_1000") %>%
  mutate(lat = as.numeric(lat), lon = as.numeric(lon)) %>%
  mutate(lon = ifelse(lon > 180, lon - 360, lon)) %>%
  mutate(poc_1000 = ifelse(poc_1000 == 0, NA, poc_1000))

# Join together
df_c_mod <- poc_exp %>% 
  left_join(poc_100, by = join_by(lat, lon)) %>% 
  left_join(poc_1000, by = join_by(lat, lon))

# Plot maps
df_c_mod %>% 
  pivot_longer(poc_exp:poc_1000, values_to = "poc") %>% 
  mutate(name = factor(name, levels = c("poc_exp", "poc_100", "poc_1000"))) %>% 
  ggplot() +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  geom_raster(aes(x = lon, y = lat, fill = poc)) +
  scale_fill_cmocean(name = "matter", na.value = NA, trans = "log1p") +
  coord_quickmap(expand = 0) +
  facet_wrap(~name, ncol = 1)

# Map of POC1000
df_c_mod %>% 
  ggplot() +
  geom_raster(aes(x = lon, y = lat, fill = poc_1000)) +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  scale_fill_cmocean(name = "matter", na.value = NA) +
  coord_quickmap(expand = 0)
```

### Compute attenuation

We only have 3 depths: 73m, 100m and 1000m. Thus to compute attenuation we compute the ratio POC_1000 / POC_73 (bottom of euphotic layer in the model):

-   `remain = poc_1000 / poc_exp` shows what’s remain from the exported POC (close to 0  where there is \~nothing left)

-   `att = 1 - remain` is the actual attenuation (close to 1  where there is \~nothing left)

The `attenuation` makes more sense but the distribution of `remaining` will be much easier to predict (after a log-transformation).

```{r att_wang}
df_c_mod <- df_c_mod %>% 
  mutate(
    remain = poc_1000 / poc_exp,
    att = 1 - remain
  )

# Plot it
ggplot(df_c_mod) + 
  geom_raster(aes(x = lon, y = lat, fill = remain)) +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  ggplot2::scale_fill_viridis_c(na.value = NA) +
  labs(fill = "Remaining") +
  coord_quickmap(expand = 0)

ggplot(df_c_mod) + 
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  geom_raster(aes(x = lon, y = lat, fill = att)) +
  ggplot2::scale_fill_viridis_c(na.value = NA) +
  labs(fill = "Attenuation") +
  coord_quickmap(expand = 0)
```

At low latitudes, attenuation is close to 0: POC_1000 is very low compared to what was exported.

## GlobeSink (ARGO)

### Read data

This is a gridded climatology with poc values for lon, lat and depth.

```{r read_argo}
library(raveio)
# Open mat file
globe <- read_mat("data/raw/BGC_Argo_monthly_maps_GLOBESINK_global_beta20240212auto_baseline_QC_only_fluxes.mat")

# Read POC data
# NB: these are mg C m-2 day-1, same as Wang
poc_l <- globe$`monthly_maps/flux/POC_l`
poc_s <- globe$`monthly_maps/flux/POC_s`

# Read coordinates
#  compute bin centres from edges
depths <- globe$zbin_edges[1,]
depths <- head(depths, -1) + (diff(depths) / 2)
lats <- globe$lat_edges[1,]
lats <- head(lats, -1) + (diff(lats))/2
lons <- globe$lon_edges[1,]
lons <- head(lons, -1) + (diff(lons))/2

# Reorder POC dimensions to lon, lat, depth, month
poc_l <- aperm(poc_l, c(3, 2, 1, 4))
poc_s <- aperm(poc_s, c(3, 2, 1, 4))

# Compute annual mean at all depth
poc_l <- apply(poc_l, c(1, 2, 3), mean, na.rm = TRUE)
poc_s <- apply(poc_s, c(1, 2, 3), mean, na.rm = TRUE)

## Convert to dataframe
# store matrices into a single object
poc <- c()
poc$poc_l <- poc_l
poc$poc_s <- poc_s

# unroll each matrix
poc_v <- lapply(poc, function(e) { as.vector(e) })
# combine as columns
df_c_argo <- do.call(cbind, poc_v) %>% as.data.frame() %>% setNames(names(poc_v))

# add coordinates (NB: shorter elements are recycled automatically)
df_c_argo$lon <- lons
df_c_argo$lat <- rep(lats, each = length(lons))
df_c_argo$depth <- rep(depths, each = length(lons) * length(lats))

# Reorder and compute total poc
df_c_argo <- df_c_argo %>% 
  mutate(poc_tot = poc_s + poc_l) %>% 
  select(lon, lat, depth, poc = poc_tot) %>% 
  as_tibble()

# Keep only values above 1000 m
df_c_argo <- df_c_argo %>% filter(depth <= 1000)
unique(df_c_argo$depth)

# Plot a map of the 50-100 m bin
df_c_argo %>% 
  filter(depth == 75) %>% 
  ggplot() +
  geom_raster(aes(x = lon, y = lat, fill = poc)) +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  scale_fill_cmocean(name = "matter", na.value = NA, trans = "log1p") +
  coord_quickmap(expand = 0)
```

### Compute attenuation

To compute attenuation, we fit Martin’s curve, i.e. find the b-value for

F~z~ = F~z0~(z/z0)^b^

::: callout-important
Need to filter poor fits? Set a threshold on adjusted R²?
:::

```{r att_argo}
# Reference depth 75 m
z0 <- 75

# Unique identifier for pixels
df_c_argo <- df_c_argo %>% 
  select(lon, lat, depth, poc) %>% 
  mutate(pix_id = paste0("lon ", lon, " lat ", lat), .before = lon) %>% 
  filter(depth >= z0)

## At least 5 obs to fit an attenuation
# Drop pixels with no data
df_c_argo <- df_c_argo %>% 
  group_by(pix_id, lon, lat) %>% 
  mutate(n_obs = sum(!is.na(poc))) %>% 
  ungroup() %>% 
  filter(n_obs >=5) %>% 
  select(-n_obs) %>% 
  rename(z = depth)

# Select a few pixels for plots
pix_plot <- df_c_argo %>% select(pix_id) %>% unique() %>% slice_sample(n = 16) %>% pull(pix_id)

# Perform linear regression on log-transformed data
argo_regs <- df_c_argo %>% 
  nest(data = c(poc, z)) %>% 
  mutate(
    fit = map(data, ~lm(log(poc) ~ log(z/z0), data = .x)),
    glance = map(fit, glance),
    tidied = map(fit, tidy)    
  )

# glance contains all summary of fits
argo_summ <- argo_regs %>%   
  select(pix_id, lon, lat, glance) %>%
  unnest(glance)

# tidied contains coefficients
argo_coef <- argo_regs %>%
  select(pix_id, lon, lat, tidied) %>%
  unnest(tidied) %>%
  # keep only estimates of slope and intercept
  select(-c(std.error, statistic, p.value)) %>%
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "intercept",
      .default = "b"
  )) %>% 
  # 2 rows (intercept + slope) for each profile, reshape to make it 1 row
  pivot_wider(names_from = term, values_from = estimate) %>% 
  # make b positive
  mutate(b = -b)


# Let’s join both together
argo_coef <- argo_coef %>% left_join(argo_summ, by = join_by(pix_id, lon, lat))

# Plot a few fits
b_curve <- crossing(
  pix_id = unique(df_c_argo$pix_id),
  z = seq(from = 75, to = 2000, by = 5)
  ) %>% 
  left_join(argo_coef %>% select(pix_id, intercept, b, adj.r.squared), by = join_by(pix_id)) %>% 
  mutate(poc = exp((-b) * log(z/z0) + intercept))

ggplot(df_c_argo %>% filter(pix_id %in% pix_plot)) +
  geom_path(data = b_curve  %>% filter(pix_id %in% pix_plot), aes(x = poc, y = -z, colour = adj.r.squared), linewidth = 1) +
  geom_point(aes(x = poc, y = -z), size = 0.5) +
  scale_colour_viridis_c() +
  facet_wrap(~pix_id)

# Not too bad!


## TODO discard poor fits
# Plot distribution of adjusted R²
ggplot(argo_coef) + geom_histogram(aes(x = adj.r.squared))
# Some adjuster R² are indeed low

# Plot a few poor fits
thr <- 0.2
df_c_argo %>% 
  left_join(argo_coef, by = join_by(pix_id, lon, lat)) %>% 
  filter(adj.r.squared < thr) %>% 
  ggplot() +
  geom_path(data = b_curve  %>% filter(adj.r.squared < thr), aes(x = poc, y = -z, colour = adj.r.squared), linewidth = 1) +
  geom_point(aes(x = poc, y = -z), size = 0.5) +
  scale_colour_viridis_c() +
  facet_wrap(~pix_id)

# Try discard below 0.2

df_c_argo <- df_c_argo %>% 
  left_join(argo_coef, by = join_by(pix_id, lon, lat)) %>% 
  filter(adj.r.squared > thr) %>% 
  select(pix_id:b, adj_r2 = adj.r.squared)

## Plot maps
ggmap(df_c_argo, var = "b", type = "raster")

df_c_argo %>% 
  filter(b < 1) %>% 
  ggplot() +
  geom_tile(aes(x = lon, y = lat, fill = b)) +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "grey") +
  scale_fill_viridis_c() +
  coord_quickmap(expand = 0)


ggmap(df_c_argo, var = "adj_r2", type = "raster")
```

### Reformat

Keep POC at bottom of euphotic layer and a bit above 1000 m, as well as POC attenuation.

Make sure that we have a complete grid of lon and lat, fill with NA if needed.

```{r reformat_argo}
# Keep 2 depths + attenuation
df_c_argo <- df_c_argo %>% 
  filter(z == 75 | z == 937.5) %>% 
  select(lon, lat, depth = z, poc, att = b) %>% 
  mutate(
    depth = ifelse(depth == 75, "poc_exp", "poc_1000")
  ) %>% 
  pivot_wider(names_from = "depth", values_from = "poc")

# Generate a complete grid
df_c_argo <- crossing(lon = lons, lat = lats) %>% 
  left_join(df_c_argo, by = join_by(lon, lat))

ggmap(df_c_argo, var = "poc_exp", type = "raster")
ggmap(df_c_argo, var = "poc_1000", type = "raster")
ggmap(df_c_argo, var = "att", type = "raster")
```

::: callout-note
Resolution is too coarse.
:::

## Canyon (ARGO + sat + ML) − Sauzède et al.

### Read data

#### Read nc files

```{r read_can}
# List NC files to read
files <- list.files("data/raw/soca/", full.names = TRUE)

# Open one file to get dims
nc <- nc_open(files[1])
lon <- ncvar_get(nc, "longitude")
lat <- ncvar_get(nc, "latitude")
depth <- ncvar_get(nc, "depth")
nc_close(nc)

# Prepare storage for 12 months
poc_mo <- array(NA, c(length(lon), length(lat), length(depth), 12))
# Read all files
for(i in 1:12) {
  # get relevant files
  file <- files[i]
  # open the file and read the data in it
  nc <- nc_open(file)
  poc_mo[,,,i] <- ncvar_get(nc, "poc")
  nc_close(nc)
}

# Plot surface POC in January
image.plot(poc_mo[,,1,1], col = col_poc)
```

Looks good, compute annual climatology from mensual data.

#### Compute annual climatology

```{r ann_clim}
# Do it parallel on depth
poc_ann <- mclapply(1:length(depth), function(d) {
  # Get one layer
  s_block <- poc_mo[,,d,]
  # Compute annual mean for each pixel
  return(apply(s_block, c(1, 2), mean, na.rm = TRUE))
}, mc.cores = n_cores) %>%
  abind(along = 3)

# Plot surface climatology
image.plot(poc_ann[,,1], col = col_poc)
# Plot 1000 m climatology
image.plot(poc_ann[,,35], col = col_poc)
```

#### Convert to dataframe

```{r to_df}
# To vector and to single column df
df_can <- poc_ann %>% as.vector() %>% as.data.frame() %>% setNames("poc")
# Add lon, lat and depth
df_can$lon <- lon
df_can$lat <- rep(lat, each=length(lon))
df_can$depth <- rep(depth, each=length(lon)*length(lat))
# Convert to tibble
df_can <- df_can %>% as_tibble() %>% select(lon, lat, depth, poc)

# Plot surface map
df_can %>%
  filter(depth == 0) %>%
  ggplot() +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "grey") +
  geom_tile(aes(x = lon, y = lat, colour = poc, fill = poc)) +
  scale_colour_cmocean(name = "matter", na.value = NA) + 
  scale_fill_cmocean(name = "matter", na.value = NA) + 
  labs(title = "Surface POC") +
  coord_quickmap(expand = 0)
```

### Compute attenuation as Martin’s b

Compute attenuation on a few profiles and generate some plots.

```{r can_martin}
#| fig-column: screen-inset
#| out-width: 100%
#| fig-width: 10
#| fig-height: 10
# Drop pixels with only NA and generate unique pixel id
df_can <- df_can %>%
  drop_na(poc) %>%
  mutate(pix_id = paste0(lon, "_", lat), .before = lon)

# Select a few profiles for plotting
# Originally 515000 profiles
sel_pix <- df_can %>%
  filter(depth == 0) %>%
  slice_sample(n = 49)
df_can_sub <- df_can %>%
  filter(pix_id %in% sel_pix$pix_id)

# Find reference depth as the depth with maximum poc
df_can_sub <- df_can_sub %>%
  arrange(pix_id,) %>% 
  group_by(pix_id, lon, lat) %>% 
  mutate(
    poc_max = cummax(poc),
    keep = poc_max == max(poc)
  ) %>% 
  filter(keep) %>% 
  mutate(z0 = min(depth)) %>% 
  ungroup() %>% 
  select(-c(poc_max, keep))

# Perform linear regression on log-transformed data
argo_regs <- df_can_sub %>%
  #filter(depth >= z0) %>%
  rename(z = depth) %>%
  arrange(pix_id) %>%
  nest(data = c(poc, z, z0)) %>%
  mutate(
    fit = map(data, ~lm(log(poc) ~ log(z/z0), data = .x)),
    glance = map(fit, glance),
    tidied = map(fit, tidy)
  )

# glance contains all summary of fits
argo_summ <- argo_regs %>%
  select(pix_id, lon, lat, glance) %>%
  unnest(glance)

# tidied contains coefficients
argo_coef <- argo_regs %>%
  select(pix_id, lon, lat, tidied) %>%
  unnest(tidied) %>%
  # keep only estimates of slope and intercept
  select(-c(std.error, statistic, p.value)) %>%
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "intercept",
      .default = "b"
    )) %>%
  # 2 rows (intercept + slope) for each profile, reshape to make it 1 row
  pivot_wider(names_from = term, values_from = estimate)

# Let’s join both together
argo_coef <- argo_coef %>% left_join(argo_summ, by = join_by(pix_id, lon, lat))

# Make b positive
argo_coef <- argo_coef %>% mutate(b = -b)

# Plot a few fits
# Generate data
b_curve <- df_can_sub %>% 
  select(pix_id, lon, lat, z = depth, z0) %>% 
  left_join(
    argo_coef %>% select(pix_id, intercept, b, adj.r.squared), 
    by = join_by(pix_id)
  ) %>% 
   mutate(poc = exp((-b) * log(z/z0) + intercept))
# Plo it
ggplot() +
  geom_path(data = b_curve, aes(x = poc, y = -z, colour = b), linewidth = 1) +
  geom_point(data = df_can_sub, aes(x = poc, y = -depth), size = 0.5) +
  scale_colour_viridis_c() +
  facet_wrap(~pix_id)
```

Look at trends of b value in 1/5 of the whole dataset.

```{r b_trend}
#| fig-column: body-outset
#| out-width: 100%
# Get 1/5 pix in both lon and lat to plot map of b values
df_can_map <- df_can %>% 
  #select(pix_id, lon, lat) %>% 
  #unique() %>% 
  arrange(lat) %>% 
  group_by(lat) %>% 
  mutate(lat_id = cur_group_id()) %>% 
  ungroup() %>% 
  arrange(lon) %>% 
  group_by(lon) %>% 
  mutate(lon_id = cur_group_id()) %>% 
  ungroup() %>% 
  filter(lon_id %% 5 == 0) %>% 
  filter(lat_id %% 5 == 0) %>% 
  select(-c(lat_id, lon_id))

# Compute reference depth
df_can_map <- df_can_map %>%
  filter(depth > 0) %>% # reference depth cannot be 0
  arrange(pix_id,) %>% 
  group_by(pix_id, lon, lat) %>% 
  mutate(
    poc_max = cummax(poc),
    keep = poc_max == max(poc)
  ) %>% 
  filter(keep) %>% 
  mutate(z0 = min(depth)) %>% 
  ungroup() %>% 
  select(-c(poc_max, keep))

# Perform linear regression on log-transformed data
argo_map_regs <- df_can_map %>%
  #filter(depth >= z0) %>%
  rename(z = depth) %>%
  arrange(pix_id) %>%
  nest(data = c(poc, z, z0)) %>%
  mutate(
    fit = map(data, ~lm(log(poc) ~ log(z/z0), data = .x)),
    glance = map(fit, glance),
    tidied = map(fit, tidy)
  )

# glance contains all summary of fits
argo_map_summ <- argo_map_regs %>%
  select(pix_id, lon, lat, glance) %>%
  unnest(glance)

# tidied contains coefficients
argo_map_coef <- argo_map_regs %>%
  select(pix_id, lon, lat, tidied) %>%
  unnest(tidied) %>%
  # keep only estimates of slope and intercept
  select(-c(std.error, statistic, p.value)) %>%
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "intercept",
      .default = "b"
    )) %>%
  # 2 rows (intercept + slope) for each profile, reshape to make it 1 row
  pivot_wider(names_from = term, values_from = estimate)


# Let’s join both together
argo_map_coef <- argo_map_coef %>% left_join(argo_map_summ, by = join_by(pix_id, lon, lat))

# Make b positive
argo_map_coef <- argo_map_coef %>% mutate(b = -b)

# Plot map of b value
argo_map_coef %>% 
  ggplot() + 
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "grey") +
  geom_tile(aes(x = lon, y = lat, fill = b, colour = b)) +
  scale_fill_viridis_c() +
  scale_colour_viridis_c() +
  coord_quickmap(expand = 0)
```

Compute attenuation for locations of UVP profiles.

```{r b_uvp}
#| fig-column: body-outset
#| out-width: 100%
# Load UVP data
load("data/01.uvp_profiles.Rdata")

# Match lon and lat to POC dataset
profiles_r <- profiles %>%
  select(lon, lat) %>% 
  mutate(
    lon = roundp(profiles$lon, precision = 0.25, f = floor) + 0.125,
    lat = roundp(profiles$lat, precision = 0.25, f = floor) + 0.125
  ) %>% 
  # Keep only unique pixels
  distinct()

# Get corresponding POC profiles
df_can_uvp <- profiles_r %>% 
  left_join(df_can, by = join_by(lon, lat)) %>% 
  drop_na(poc)

# Compute reference depth
df_can_uvp <- df_can_uvp %>%
  filter(depth > 0) %>% # reference depth cannot be 0
  group_by(lon, lat) %>% 
  mutate(
    poc_max = cummax(poc),
    keep = poc_max == max(poc)
  ) %>% 
  filter(keep) %>% 
  mutate(z0 = min(depth)) %>% 
  ungroup() %>% 
  select(-c(poc_max, keep))

# Perform linear regression on log-transformed data
argo_uvp_regs <- df_can_uvp %>%
  filter(depth >= z0) %>%
  rename(z = depth) %>%
  nest(data = c(poc, z, z0)) %>%
  mutate(
    fit = map(data, ~lm(log(poc) ~ log(z/z0), data = .x)),
    glance = map(fit, glance),
    tidied = map(fit, tidy)
  )

# glance contains all summary of fits
argo_uvp_summ <- argo_uvp_regs %>%
  select(lon, lat, glance) %>%
  unnest(glance)

# tidied contains coefficients
argo_uvp_coef <- argo_uvp_regs %>%
  select(lon, lat, tidied) %>%
  unnest(tidied) %>%
  # keep only estimates of slope and intercept
  select(-c(std.error, statistic, p.value)) %>%
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "intercept",
      .default = "b"
    )) %>%
  # 2 rows (intercept + slope) for each profile, reshape to make it 1 row
  pivot_wider(names_from = term, values_from = estimate)

# Make b positive
argo_uvp_coef <- argo_uvp_coef %>% mutate(b = -b)

# Join UVP with POC b values and drop profiles with no b value
df_c_can <- profiles_r %>% 
  left_join(argo_uvp_coef %>% select(lon, lat, att = b), by = join_by(lon, lat)) %>% 
  drop_na(att)

# Plot map of profiles
ggplot(df_c_can) +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "grey") +
  geom_point(aes(x = lon, y = lat, colour = att), size = 0.5) +
  scale_colour_viridis_c() +
  labs(title = "Map of b values for UVP dataset") +
  coord_quickmap(expand = 0)

# Plot latitudinal trend
ggplot(df_c_can, aes(x = lat, y = att)) +
  geom_point(size = 0.5) +
  geom_smooth() +
  coord_flip()

# Distribution of b-value
ggplot(df_c_can) + geom_histogram(aes(x = att), bins = 100)
```

## Save

```{r save}
save(df_c_mod, df_c_argo, df_c_can, file = "data/02.carbon_data.Rdata")
```
