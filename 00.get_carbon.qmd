---
title: "Prepare carbon export data"
format:
  html:
    toc: true
editor: visual
---

```{r set_up}
#| output: false
source("utils.R")
```

## Model data (Wang et al.)

### Read data

```{r read_wang}
#| fig-column: body-outset
#| out-width: 100%
poc_exp <- readMat("data/raw/Cexp_CAFE_kl24h.mat")$EXP[,,1]$POCexp
poc_100 <- readMat("data/raw/Cexp_CAFE_kl24h.mat")$EXP[,,1]$POC100
poc_1000 <- readMat("data/raw/Cexp_CAFE_kl24h.mat")$EXP[,,1]$POC1000

# Generate colnames as longitudes and rownames as latitudes
colnames(poc_exp) <- (c(0.5:179.5) * 2)
colnames(poc_100) <- (c(0.5:179.5) * 2)
colnames(poc_1000) <- (c(0.5:179.5) * 2)

rownames(poc_exp) <- (c(0:90) * 2) - 90
rownames(poc_100) <- (c(0:90) * 2) - 90
rownames(poc_1000) <- (c(0:90) * 2) - 90

# Convert to dataframes
poc_exp <- poc_exp %>%
  as.data.frame() %>%
  rownames_to_column(var = "lat") %>%
  as_tibble() %>%
  pivot_longer(cols = -lat, names_to = "lon", values_to = "poc_exp") %>%
  mutate(lat = as.numeric(lat), lon = as.numeric(lon)) %>%
  mutate(lon = ifelse(lon > 180, lon - 360, lon)) %>%
  mutate(poc_exp = ifelse(poc_exp == 0, NA, poc_exp)) 

poc_100 <- poc_100 %>%
  as.data.frame() %>%
  rownames_to_column(var = "lat") %>%
  as_tibble() %>%
  pivot_longer(cols = -lat, names_to = "lon", values_to = "poc_100") %>%
  mutate(lat = as.numeric(lat), lon = as.numeric(lon)) %>%
  mutate(lon = ifelse(lon > 180, lon - 360, lon)) %>%
  mutate(poc_100 = ifelse(poc_100 == 0, NA, poc_100)) 

poc_1000 <- poc_1000 %>%
  as.data.frame() %>%
  rownames_to_column(var = "lat") %>%
  as_tibble() %>%
  pivot_longer(cols = -lat, names_to = "lon", values_to = "poc_1000") %>%
  mutate(lat = as.numeric(lat), lon = as.numeric(lon)) %>%
  mutate(lon = ifelse(lon > 180, lon - 360, lon)) %>%
  mutate(poc_1000 = ifelse(poc_1000 == 0, NA, poc_1000))

# Join together
df_c_mod <- poc_exp %>% 
  left_join(poc_100, by = join_by(lat, lon)) %>% 
  left_join(poc_1000, by = join_by(lat, lon))

# Plot maps
df_c_mod %>% 
  pivot_longer(poc_exp:poc_1000, values_to = "poc") %>% 
  mutate(name = factor(name, levels = c("poc_exp", "poc_100", "poc_1000"))) %>% 
  ggplot() +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  geom_raster(aes(x = lon, y = lat, fill = poc)) +
  scale_fill_cmocean(name = "matter", na.value = NA, trans = "log1p") +
  coord_quickmap(expand = 0) +
  facet_wrap(~name, ncol = 1)
```

### Compute attenuation

We only have 3 depths: 73m, 100m and 1000m. Thus to compute attenuation we compute the ratio POC_1000 / POC_73 (bottom of euphotic layer in the model):

-   `remain = poc_1000 / poc_exp` shows what’s remain from the exported POC (close to 0  where there is \~nothing left)

-   `att = 1 - remain` is the actual attenuation (close to 1  where there is \~nothing left)

The `attenuation` makes more sense but the distribution of `remaining` will be much easier to predict (after a log-transformation).

```{r att_wang}
df_c_mod <- df_c_mod %>% 
  mutate(
    remain = poc_1000 / poc_exp,
    att = 1 - remain
  )

# Plot it
ggplot(df_c_mod) + 
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  geom_raster(aes(x = lon, y = lat, fill = remain)) +
  ggplot2::scale_fill_viridis_c(na.value = NA) +
  labs(fill = "Remaining") +
  coord_quickmap(expand = 0)

ggplot(df_c_mod) + 
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  geom_raster(aes(x = lon, y = lat, fill = att)) +
  ggplot2::scale_fill_viridis_c(na.value = NA) +
  labs(fill = "Attenuation") +
  coord_quickmap(expand = 0)
```

At low latitudes, attenuation is close to 0: POC_1000 is very low compared to what was exported.

## Observation data (ARGO)

### Read data

This is a gridded climatology with poc values for lon, lat and depth.

```{r read_argo}
library(raveio)
# Open mat file
globe <- read_mat("data/raw/BGC_Argo_monthly_maps_GLOBESINK_global_beta20240212auto_baseline_QC_only_fluxes.mat")

# Read POC data
# NB: these are mg C m-2 day-1, same as Wang
poc_l <- globe$`monthly_maps/flux/POC_l`
poc_s <- globe$`monthly_maps/flux/POC_s`

# Read coordinates
#  compute bin centres from edges
depths <- globe$zbin_edges[1,]
depths <- head(depths, -1) + (diff(depths) / 2)
lats <- globe$lat_edges[1,]
lats <- head(lats, -1) + (diff(lats))/2
lons <- globe$lon_edges[1,]
lons <- head(lons, -1) + (diff(lons))/2

# Reorder POC dimensions to lon, lat, depth, month
poc_l <- aperm(poc_l, c(3, 2, 1, 4))
poc_s <- aperm(poc_s, c(3, 2, 1, 4))

# Compute annual mean at all depth
poc_l <- apply(poc_l, c(1, 2, 3), mean, na.rm = TRUE)
poc_s <- apply(poc_s, c(1, 2, 3), mean, na.rm = TRUE)

## Convert to dataframe
# store matrices into a single object
poc <- c()
poc$poc_l <- poc_l
poc$poc_s <- poc_s

# unroll each matrix
poc_v <- lapply(poc, function(e) { as.vector(e) })
# combine as columns
df_c_argo <- do.call(cbind, poc_v) %>% as.data.frame() %>% setNames(names(poc_v))

# add coordinates (NB: shorter elements are recycled automatically)
df_c_argo$lon <- lons
df_c_argo$lat <- rep(lats, each = length(lons))
df_c_argo$depth <- rep(depths, each = length(lons) * length(lats))

# Reorder and compute total poc
df_c_argo <- df_c_argo %>% 
  mutate(poc_tot = poc_s + poc_l) %>% 
  select(lon, lat, depth, poc = poc_tot) %>% 
  as_tibble()

# Keep only values above 1000 m
df_c_argo <- df_c_argo %>% filter(depth <= 1000)
unique(df_c_argo$depth)

# Plot a map of the 50-100 m bin
df_c_argo %>% 
  filter(depth == 75) %>% 
  ggplot() +
  geom_polygon(data = world, aes(x = lon, y = lat, group = group), fill = "gray") +
  geom_raster(aes(x = lon, y = lat, fill = poc)) +
  scale_fill_cmocean(name = "matter", na.value = NA, trans = "log1p") +
  coord_quickmap(expand = 0)
```

### Compute attenuation

To compute attenuation, we fit Martin’s curve, i.e. find the b-value for

F~z~ = F~z0~(z/z0)^b^

::: callout-important
Need to filter poor fits? Set a threshold on adjusted R²?
:::

```{r att_argo}
# Reference depth 75 m
z0 <- 75

# Unique identifier for pixels
df_c_argo <- df_c_argo %>% 
  select(lon, lat, depth, poc) %>% 
  mutate(pix_id = paste0("lon ", lon, " lat ", lat), .before = lon) %>% 
  filter(depth >= z0)

## At least 5 obs to fit an attenuation
# Drop pixels with no data
df_c_argo <- df_c_argo %>% 
  group_by(pix_id, lon, lat) %>% 
  mutate(n_obs = sum(!is.na(poc))) %>% 
  ungroup() %>% 
  filter(n_obs >=5) %>% 
  select(-n_obs) %>% 
  rename(z = depth)

# Select a few pixels for plots
pix_plot <- df_c_argo %>% select(pix_id) %>% unique() %>% slice_sample(n = 16) %>% pull(pix_id)

# Perform linear regression on log-transformed data
argo_regs <- df_c_argo %>% 
  nest(data = c(poc, z)) %>% 
  mutate(
    fit = map(data, ~lm(log(poc) ~ log(z/z0), data = .x)),
    glance = map(fit, glance),
    tidied = map(fit, tidy)    
  )

# glance contains all summary of fits
argo_summ <- argo_regs %>%   
  select(pix_id, lon, lat, glance) %>%
  unnest(glance)

# tidied contains coefficients
argo_coef <- argo_regs %>%
  select(pix_id, lon, lat, tidied) %>%
  unnest(tidied) %>%
  # keep only estimates of slope and intercept
  select(-c(std.error, statistic, p.value)) %>%
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "intercept",
      .default = "b"
  )) %>% 
  # 2 rows (intercept + slope) for each profile, reshape to make it 1 row
  pivot_wider(names_from = term, values_from = estimate)


# Let’s join both together
argo_coef <- argo_coef %>% left_join(argo_summ, by = join_by(pix_id, lon, lat))

# Plot a few fits
b_curve <- crossing(
  pix_id = unique(df_c_argo$pix_id),
  z = seq(from = 75, to = 2000, by = 5)
  ) %>% 
  left_join(argo_coef %>% select(pix_id, intercept, b, adj.r.squared), by = join_by(pix_id)) %>% 
  mutate(poc = exp(b * log(z/z0) + intercept))

ggplot(df_c_argo %>% filter(pix_id %in% pix_plot)) +
  geom_path(data = b_curve  %>% filter(pix_id %in% pix_plot), aes(x = poc, y = -z, colour = adj.r.squared), linewidth = 1) +
  geom_point(aes(x = poc, y = -z), size = 0.5) +
  scale_colour_viridis_c() +
  facet_wrap(~pix_id)

# Not too bad!


## TODO discard poor fits
# Plot distribution of adjusted R²
ggplot(argo_coef) + geom_histogram(aes(x = adj.r.squared))
# Some adjuster R² are indeed low

# Plot a few poor fits
thr <- 0.2
df_c_argo %>% 
  left_join(argo_coef, by = join_by(pix_id, lon, lat)) %>% 
  filter(adj.r.squared < thr) %>% 
  ggplot() +
  geom_path(data = b_curve  %>% filter(adj.r.squared < thr), aes(x = poc, y = -z, colour = adj.r.squared), linewidth = 1) +
  geom_point(aes(x = poc, y = -z), size = 0.5) +
  scale_colour_viridis_c() +
  facet_wrap(~pix_id)

# Try discard below 0.2

df_c_argo <- df_c_argo %>% 
  left_join(argo_coef, by = join_by(pix_id, lon, lat)) %>% 
  filter(adj.r.squared > thr) %>% 
  select(pix_id:b, adj_r2 = adj.r.squared)

## Plot maps
ggmap(df_c_argo, var = "b", type = "raster")
ggmap(df_c_argo, var = "adj_r2", type = "raster")
```

### Reformat

Keep POC at bottom of euphotic layer and a bit above 1000 m, as well as POC attenuation.

Make sure that we have a complete grid of lon and lat, fill with NA if needed.

```{r reformat_argo}
# Keep 2 depths + attenuation
df_c_argo <- df_c_argo %>% 
  filter(z == 75 | z == 937.5) %>% 
  select(lon, lat, depth = z, poc, att = b) %>% 
  mutate(
    depth = ifelse(depth == 75, "poc_exp", "poc_1000")
  ) %>% 
  pivot_wider(names_from = "depth", values_from = "poc")

# Generate a complete grid
df_c_argo <- crossing(lon = lons, lat = lats) %>% 
  left_join(df_c_argo, by = join_by(lon, lat))

ggmap(df_c_argo, var = "poc_exp", type = "raster")
ggmap(df_c_argo, var = "poc_1000", type = "raster")
ggmap(df_c_argo, var = "att", type = "raster")
```

## Save

```{r save}
save(df_c_mod, df_c_argo, file = "data/00.carbon_data.Rdata")
```
