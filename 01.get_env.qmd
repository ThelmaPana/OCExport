---
title: "Prepare environmental data"
format:
  html:
    toc: true
editor: visual
---

```{r}
#| output: false
source("utils.R")
```

## WOA data

### Download

Perform only if necessary.

```{r}
if (download_woa){
  # define all combinations of variables to download
  df <- read_csv(
    "var,abbrv,period
    temperature,t,A5B7
    salinity,s,A5B7
    AOU,A,all
    silicate,i,all
    phosphate,p,all
    nitrate,n,all
    oxygen,o,all
  ")
  month <- sprintf("%02i",1:12)
  combi <- crossing(df, month)

  # define download URLs
  urls <- glue("https://data.nodc.noaa.gov/thredds/fileServer/ncei/woa/{var}/{period}/1.00/woa18_{period}_{abbrv}{month}_01.nc", .envir = combi)

  # and download files
  lapply(urls, function(url) {
    message(basename(url))
    download.file(url, destfile=file.path(woa_dir, basename(url)))
    Sys.sleep(10)
  })
  message("Done downloading WOA data")

  # create links to the downloaded files with easier names
  ok <- file.symlink(
    from = glue("{woa_dir}/woa18_{period}_{abbrv}{month}_01.nc", .envir = combi),
    to = file.path(woa_loc, glue("{var}_{month}.nc", .envir = mutate(combi, month = as.numeric(month))))
  )
  all(ok)
}
```

### Read

```{r}
# List WOA variables
vars <- c("temperature", "salinity", "silicate", "phosphate", "nitrate", "oxygen")

# Open one file to get all coordinates (lon, lat, depth)
nc <- nc_open(file.path(woa_loc, "temperature_1.nc"))
lon <- ncvar_get(nc, "lon")
lat <- ncvar_get(nc, "lat")
depth <- ncvar_get(nc, "depth")
# Get indexes of relevant depth
depth_idx <- which(depth <= max_depth_woa)
# Limit depth to chosen max depth
depth <- ncvar_get(nc, "depth", count = max(depth_idx))
# Number of depth values
depth_count <- max(depth_idx)
# Close the file
nc_close(nc)

# Read all files in parallel
woa <- mclapply(vars, function(var) {
  # prepare storage for one variable at n depths for 12 months
  block <- array(NA, c(360, 180, depth_count, 12))

  for (month in 1:12) {
    # define the file to read
    file <- str_c(woa_loc, "/", var, "_", month, ".nc")
    # open the file and read the data in it
    nc <- nc_open(file)
    block[,,,month] <- ncvar_get(nc, varid=names(nc$var)[6], count = c(360, 180, depth_count, 1))
    nc_close(nc)
  }
  return(block)
}, mc.cores = min(length(vars), n_cores))

# Add variable names
names(woa) <- vars
```

Plot surface values for January.

```{r}
image.plot(woa$temperature[,,1,1], col = col_temp, main = "Temperature")
image.plot(woa$salinity[,,1,1], col = col_sal, main = "Salinity")
image.plot(woa$oxygen[,,1,1], col = col_oxy, main = "Oxygen")
image.plot(woa$nitrate[,,1,1], col = col_nit, main = "Nitrate")
image.plot(woa$phosphate[,,1,1], col = col_phos, main = "Phosphate")
image.plot(woa$silicate[,,1,1], col = col_sil, main = "Silicate")
```

### MLD and pycnocline

#### Density from T and S

```{r}
# Compute pressure rather than depth
press <- array(NA, dim = dim(woa$temperature)[1:3])

# compute for one longitude
for (j in seq(along = lat)) {
  press[1,j,] <- swPressure(depth[1:depth_count], latitude = lat[j])
}
# replicate for all longitudes
for (i in seq(along = lon)) {
  press[i,,] <- press[1,,]
}

# derive potential density anomaly using oce package
woa$density <- mclapply(1:12, function(m) { # in parallel
  dens <- array(NA, dim = dim(woa$temperature)[1:3])
  for (i in seq(along = lon)) {
    for (j in seq(along = lat)) {
      dens[i,j,] <- swSigma0(
        woa$salinity[i,j,,m],
        woa$temperature[i,j,,m],
        press[i,j,], lon[i], lat[j]
        )
    }
  }
  return(dens)
}, mc.cores = n_cores)
woa$density <- do.call(abind, list(woa$density, along = 4))
```

Plot surface density in  Jan.

```{r}
image.plot(woa$density[,,1,1], col = col_dens, main = "Density")
```

#### Density clines

For this, we use data down to `r max_depth_woa` metres.

Let’s start by just selecting a few profiles, compute both MLD and pycnocline and plot them.

```{r}
# Select profiles regurlarly spaced in lon and months
sub <- data.frame()
for (y in c(30, 60, 90, 120, 170)) {
  for (m in c(1, 3, 5, 7, 9, 11)) {
    sub <- bind_rows(sub, data.frame(dens = woa$density[50,y,,m], y = y, m = m))
  }
}

# Compute clines for these profiles
ssub <- sub %>%
  # group by lon and month
  group_by(y, m) %>%
  do({
    d <- .$dens # get density
    ok <- !is.na(d) # drop NAs
    # sequence of regular depth for interpolation
    depths_i <- seq(0, max_depth_woa, by = 5) 
    # interpolate density on these depths
    dens_i <- interpolate(depth[ok], d[ok], depths_i, method = "spline", extrapolate=FALSE)
    # compute pycnocline, i.e. maximum variance using a moving window
    pyc <- clined(dens_i, depths_i, n.smooth = 2, k = 4)
    # compute MLD
    mld <- mld(dens_i, depths_i, ref.depths = 0:15, n.smooth = 2, k = 4)
    # store all this in a dataframe
    data.frame(depth = depths_i, dens = dens_i, pyc = pyc, mld = mld, id = str_c(.$y[1], "-",.$m[1]))
})

# Plots results
ggplot(ssub) +
  geom_path(aes(x = dens, y = -depth)) +
  geom_hline(aes(yintercept = -pyc), data = distinct(ssub, id, pyc), colour="red") +
  geom_hline(aes(yintercept = -mld), data = distinct(ssub, id, mld), colour="blue") +
  facet_wrap(~id)
```

The pycnocline seems more appropriate than the MLD, but let’s compute both for all profiles.

```{r}
# for each pixel of each month, interpolate density over depth and derive pycnocline depth
depths_i <- seq(0, max_depth_woa, by = 5)

clines <- mclapply(1:12, function(m) { # in parallel
#clines <- mclapply(c(1,7), function(m) { # test
  apply(woa$density[,,,m], c(1,2), function(dens) {
  #apply(woa$density[1:60,,,m], c(1,2), function(dens) { # test
    # dens <- woa$density[8, 30, ,9] # test
    # check number of available data points
    ok <- !is.na(dens)
    if (sum(ok) > 3) {
      # interpolate density on 5 m steps
      dens_i <- castr::interpolate(depth[ok], dens[ok], depths_i, method = "spline", extrapolate = FALSE)
      # compute pycnocline and MLD
      ok <- !is.na(dens_i)
      pyc <- clined(dens_i[ok], depths_i[ok], n.smooth = 2, k = 4)
      mld <- mld(dens_i, depths_i, ref.depths = 0:15, n.smooth = 2, k = 4)
    } else {
      pyc <- NA
      mld <- NA
    }
    return(c(pyc = pyc, mld = mld))
  })
}, mc.cores = n_cores)  # looooong, even in parallel


# Get pyc and mld from this data
mld <- vector(mode = "list", length = 12) # initate empty list for pyc and mld
pyc <- vector(mode = "list", length = 12)
for (i in 1:length(clines)){
  pyc[[i]] <- clines[[i]][1,,]
  mld[[i]] <- clines[[i]][2,,]
}

# Smooth the result to avoid local artefacts
pyc <- lapply(pyc, function(x) {
  xs <- image.smooth(x, theta = 1)$z
  return(xs)
})
mld <- lapply(mld, function(x) {
  xs <- image.smooth(x, theta = 1)$z
  return(xs)
})

# Combine all months in a matrix
pyc <- do.call(abind, list(pyc, along = 3))
mld <- do.call(abind, list(mld, along = 3))

# Plot maps
image.plot(pyc[,,1], col = col_depth, main = "Pycno")
image.plot(mld[,,1], col = col_depth, main = "MLD")
```

We should also check the distribution of these values.

```{r}
hist(pyc, breaks = 100, main = "Pycnocline")
hist(mld, breaks = 100, main = "MLD")
```

Seems to have lots of artefacts near the surface with MLD computation. Below we will try the MLD climatology from Argo Mixed Layers.

### Nutriclines

Let’s now compute clines for nitrates, phosphates and silicates.

#### Nitrates

```{r}
n_cline <- mclapply(1:12, function(m) { # in parallel
#n_cline <- mclapply(c(1,7), function(m) { # test
  apply(woa$nitrate[,,,m], c(1,2), function(nit) {
    #apply(woa$nitrate[1:60,,,m], c(1,2), function(nit) { # test
    # nit <- woa$nitrate[8, 30, ,9] # test
    # check number of available data points
    ok <- !is.na(nit)
    if (sum(ok) > 3) {
      # interpolate nitrate on 5 m steps
      nit_i <- castr::interpolate(depth[ok], nit[ok], depths_i, method = "spline", extrapolate = FALSE)
      # compute pycnocline depth
      ok <- !is.na(nit_i)
      cline <- clined(nit_i[ok], depths_i[ok], n.smooth = 2, k = 4)
    } else {
      cline <- NA
    }
    return(cline)
  })
}, mc.cores = n_cores)  # looooong, even in parallel

# smooth the result to avoid local artefacts
n_cline <- lapply(n_cline, function(x) {
  xs <- image.smooth(x, theta = 1)$z
  return(xs)
})

# combine all months into a matrix
n_cline <- do.call(abind, list(n_cline, along = 3))
image.plot(n_cline[,,1], col = col_depth, main = "Nitracline")
```

#### Phosphates

```{r}
p_cline <- mclapply(1:12, function(m) { # in parallel
#p_cline <- mclapply(c(1,7), function(m) { # test
  apply(woa$phosphate[,,,m], c(1,2), function(phos) {
    #apply(woa$phosphate[1:60,,,m], c(1,2), function(phos) { # test
    # phos <- woa$phosphate[8, 30, ,9] # test
    # check number of available data points
    ok <- !is.na(phos)
    if (sum(ok) > 3) {
      # interpolate phosphate on 5 m steps
      phos_i <- castr::interpolate(depth[ok], phos[ok], depths_i, method = "spline", extrapolate = FALSE)
      # compute pycnocline depth
      ok <- !is.na(phos_i)
      cline <- clined(phos_i[ok], depths_i[ok], n.smooth = 2, k = 4)
    } else {
      cline <- NA
    }
    return(cline)
  })
}, mc.cores = n_cores)  # looooong, even in parallel

# smooth the result to avoid local artefacts
p_cline <- lapply(p_cline, function(x) {
  xs <- image.smooth(x, theta = 1)$z
  return(xs)
})

# combine all months into a matrix
p_cline <- do.call(abind, list(p_cline, along = 3))
image.plot(p_cline[,,1], col = col_depth, main = "Phosphacline")
```

#### Silicates

```{r}
s_cline <- mclapply(1:12, function(m) { # in parallel
#s_cline <- mclapply(c(1,7), function(m) { # test
  apply(woa$silicate[,,,m], c(1,2), function(phos) {
    #apply(woa$silicate[1:60,,,m], c(1,2), function(phos) { # test
    # phos <- woa$silicate[8, 30, ,9] # test
    # check number of available data points
    ok <- !is.na(phos)
    if (sum(ok) > 3) {
      # interpolate silicate on 5 m steps
      sili_i <- castr::interpolate(depth[ok], phos[ok], depths_i, method = "spline", extrapolate = FALSE)
      # compute pycnocline depth
      ok <- !is.na(sili_i)
      cline <- clined(sili_i[ok], depths_i[ok], n.smooth = 2, k = 4)
    } else {
      cline <- NA
    }
    return(cline)
  })
}, mc.cores = n_cores)  # looooong, even in parallel

# smooth the result to avoid local artefacts
s_cline <- lapply(s_cline, function(x) {
  xs <- image.smooth(x, theta = 1)$z
  return(xs)
})

# combine all months into a matrix
s_cline <- do.call(abind, list(s_cline, along = 3))
image.plot(s_cline[,,1], col = col_depth, main = "Silicacline")
```

### Average over surface layer

For each variable, compute the average in the surface layer, i.e. from `r min(depth)` to `r layer_bottom` m.

```{r}
env_monthly <- mclapply(vars, function(var) {
  message(var)

  # extract variable
  X <- woa[[var]]

  # prepare storage
  res <- array(NA, dim(X)[-3])

  # for each pixel of each month
  for (i in seq(along = lon)) {
    for (j in seq(along = lat)) {
      for (m in 1:12) {
        # compute average if 2/3 of data is present
        keep <- X[i, j, depth <= layer_bottom, m]
        if (percent_na(keep) <= 1/3) {
          res[i, j, m] <- mean(keep, na.rm=TRUE)
        } # otherwise just leave the NA value
      }
    }
  }
  return(res)
}, mc.cores = min(length(vars), n_cores))

# Add variable names
names(env_monthly) <- vars
```

## MLD data

Let’s try data from Argo Mixed Layers: <http://mixedlayer.ucsd.edu/>.

This data uses the same grid as WOA, we can combine them together.

[TODO: which algorithm to use: density or threshold? ]{style="color: red;"}

```{r}
# Open one file to get all coordinates (lon, lat, depth)
nc <- nc_open("data/raw/mld/Argo_mixedlayers_monthlyclim_04142022.nc")

# Get lon and lat
lon_arg <- ncvar_get(nc, "lon")
lat_arg <- ncvar_get(nc, "lat")

# Get MLD values
mld_argo <- ncvar_get(nc, "mld_da_mean")

# Close the file
nc_close(nc)

# Reorder dimensions
mld_argo <- aperm(mld_argo, c(2,3,1))

# Plot
image.plot(mld_argo[,,1], col = col_depth)
```

There are missing values, let’s try smoothing to get rid of these.

```{r}
# Apply image.smooth on the 3rd dimension
mld_argo <- apply(mld_argo, 3, function(x){
  xs <- image.smooth(as.matrix(x), theta = 1)$z
  return(xs)
}, simplify = F) # we need simplify = FALSE to get back a list

# Convert list to 3D array
mld_argo <- do.call(abind, list(mld_argo, along = 3))

# Plot
image.plot(mld_argo[,,1], col = col_depth)
```

This is better, we will clean inland data below.

## Euphotic depth data

Easy one: read the `.mat` file, reshape `lon` vs `lat` and reverse `lat`. The grid is already 1°×1°×12 months.

[TODO: check grid definition. ]{style="color: red;"}

```{r}
## Euphotic zone
z_eu <- readMat("data/raw/clim4cael.mat")$z.eu
# Swap lon and lat dimensions
z_eu <- aperm(z_eu, c(2,1,3))
# Reorder lat
z_eu <- z_eu[, ncol(z_eu):1,]

# Plot for January
image.plot(z_eu[,,1], col = col_depth, main = "Euphotic depth")
```

## Irradiance data

Climatology data in 12 netcdf files. Raw resolution is very high and needs to be downgraded to a 1°×1° grid.

Let’s start by just reading 1 file to get the dimensions of the grid.

```{r}
# Open one file to get all coordinates (lon, lat)
nc <- nc_open("data/raw/modis/AQUA_MODIS.20020701_20210731.L3m.MC.PAR.par.9km.nc")
lon_par <- ncvar_get(nc, "lon")
lat_par <- ncvar_get(nc, "lat")
lat_par <- rev(lat_par) # lat will need to be reversed
nc_close(nc)
```

Now let’s read all files.

```{r}
# List par files
par_files <- list.files("data/raw/modis", full.names = TRUE, pattern = ".nc")

# Initiate empty storage for PAR
par <- array(NA, c(length(lon_par), length(lat_par), 12))

# Loop over months
for(m in 1:12){
  # open nc file
  nc <- nc_open(par_files[m])
  # read par values for a given month
  par_m <- ncvar_get(nc, "par")
  # reorder latitudes
  par[,,m] <- par_m[, ncol(par_m):1]
  # close file
  nc_close(nc)
}
```

PAR values are stored in a `r dim(par)[1]`by `r dim(par)[2]`by `r dim(par)[3]`array. To downgrade the grid, we first need to convert this data to a dataframe. Let’s process in parallel by month. For each month, floor `lon` and `lat` to 1° and add 0.5 to get the center of every pixel of the 1°×1° grid, then average PAR value per grid cell.

```{r}
# In parallel over months
par_1 <- mclapply(1:12, function(m){
  # extract data for given month
  par_m <- par[,,m]
  # set dimnames
  dimnames(par_m) <- list(lon_par, lat_par)
  # melt to dataframe
  df_par_m <- reshape2::melt(par_m) %>%
    as_tibble() %>%
    rename(lon = Var1, lat = Var2, par = value)

  # Round lon and lat to 1 degree and average per grid cell
  df_par_m <- df_par_m %>%
    mutate(
      lon = roundp(lon, precision = 1, f = floor) + 0.5,
      lat = roundp(lat, precision = 1, f = floor) + 0.5
    ) %>%
    group_by(lon, lat) %>%
    summarise(par = mean(par, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(month = m)

  return(df_par_m)
}, mc.cores = n_cores)

# Convert returned list to a tibble
par_1 <- do.call(rbind, par_1)
```

Plot a map for January.

```{r}
ggmap_ras(par_1 %>% filter(month == 1), "par")
```

This is a bit messy because of inland data but this will be cleaned below.

## Combine all env variables

Let’s combine array formatted env variables together, i.e. all variables except for PAR data.

```{r}
# Pycnocline and MLD
env_monthly$pyc <- pyc
env_monthly$mld <- mld
env_monthly$mld_argo <- mld_argo

# Nutriclines
env_monthly$n_cline <- n_cline
env_monthly$p_cline <- p_cline
env_monthly$s_cline <- s_cline

# Zeu
env_monthly$z_eu <- z_eu

# Clean dimnames
dimnames(env_monthly$pyc) <- NULL
dimnames(env_monthly$mld) <- NULL
dimnames(env_monthly$mld_argo) <- NULL
dimnames(env_monthly$n_cline) <- NULL
dimnames(env_monthly$p_cline) <- NULL
dimnames(env_monthly$s_cline) <- NULL
dimnames(env_monthly$z_eu) <- NULL
```

## Convert to dataframe

```{r}
# unroll each matrix
env_m <- lapply(env_monthly, function(e) { as.vector(e) })
# combine as columns
env_m <- do.call(cbind, env_m) %>% as.data.frame() %>% setNames(names(env_m))
# add coordinates (NB: shorter elements are recycled automatically)
env_m$lon <- lon
env_m$lat <- rep(lat, each=length(lon))
env_m$month <- rep(1:12, each=length(lon)*length(lat))
```

Then join with PAR data.

```{r}
env_m <- env_m %>% left_join(par_1, by = join_by(lon, lat, month))
```

Let’s do a quick plot to check everything is fine.

```{r}
ggmap_ras(env_m, "temperature") + facet_wrap(~month, ncol = 3)
```

## Remove internal seas, lakes and land

```{r}
# determine which points are in land
# NB: do it for one month only because those are the same for all months
env_m1 <- env_m %>% filter(month == 1)
lons <- env_m1$lon
lats <- env_m1$lat
inland <- sp::point.in.polygon(lons, lats, coast$lon, coast$lat) == 1
ggplot(env_m1) +
  geom_raster(aes(x = lon, y = lat, fill = inland)) +
  scale_fill_viridis_d() +
  scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) +
  coord_quickmap()

# remove South Pole
inland[lats < -85] <- TRUE

# remove Black Sea too
inland[between(lons, 20, 50) & between(lats, 41, 50)] <- TRUE

# remove Baltic Sea too
inland[between(lons, 12, 30) & between(lats, 52, 66)] <- TRUE

ggplot(env_m1) +
  geom_raster(aes(x = lon, y = lat, fill = inland)) +
  scale_fill_viridis_d() +
  scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) +
  coord_quickmap()

# blankout points in land
env_m[inland, !names(env_m) %in% c("lon", "lat", "month")] <- NA
# NB: this works because `inland` gets automatically repeated for everymonth

# Convert to tibble and reorder columns
env_m <- env_m %>% as_tibble() %>% select(lon, lat, month, everything())
```

[TODO: what do we do with Baltic Sea?]{style="color: red;"}

Plot a few maps without land to check.

```{r}
ggmap_ras(env_m %>% filter(month == 1), "temperature", land = FALSE)
ggmap_ras(env_m %>% filter(month == 1), "par", land = FALSE)
ggmap_ras(env_m %>% filter(month == 1), "mld", land = FALSE)
ggmap_ras(env_m %>% filter(month == 1), "mld_argo", land = FALSE)
```

Seems all good!

## Compute yearly climatology

Compute both mean and sd for each pixel.

```{r}
# Compute mean and sd per pixel
env <- env_m %>%
  select(-month) %>%
  group_by(lon, lat) %>%
  summarise_all(.funs = list(mean = mean, sd = sd), na.rm = TRUE) %>%
  ungroup()

# Reorder columns
var_names <- env_m %>% select(-c(lon, lat, month)) %>% colnames()
env <- env %>% select(c(lon, lat, str_c(var_names, "_mean"), str_c(var_names, "_sd")))
```

## Save environmental data

```{r}
save(env, file = "data/01.all_env.Rdata")
```

## Plot all maps

```{r}
# Names of env variables
var_names <- env_m %>% select(-c(lon, lat, month)) %>% colnames()
# Names of variables to plot, ordered as XXX_mean, XXX_sd, YYY_mean, YYY_sd
to_plot <- apply(expand.grid(var_names, c("_mean", "_sd")) %>% arrange(Var1), 1, paste, collapse="")

plot_list <- list()
for (i in 1:length(to_plot)){plot_list[[i]] <- ggmap_ras(env, to_plot[i])}

plot_list

```
